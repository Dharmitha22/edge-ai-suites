apiVersion: v1
data:
  ENABLE_RTSP: "true"
  RTSP_PORT: "8554"
  ENABLE_WEBRTC: "true"
  WEBRTC_SIGNALING_SERVER: "ws://localhost:8443"
  RUN_MODE: "EVA"
  GENICAM: "Balluff"
  GST_DEBUG: "1,gencamsrc:2"
  DETECTION_DEVICE: "CPU"
  CLASSIFICATION_DEVICE: "CPU"
  ADD_UTCTIME_TO_METADATA: "true"
  LSFEATURE_NAME: "dlstreamer-pipeline-server"
  HTTPS: "false"
  MTLS_VERIFICATION: "false"
  APPEND_PIPELINE_NAME_TO_PUBLISHER_TOPIC: "false"
  REST_SERVER_PORT: "8080"
  MQTT_HOST: "ibvs-broker"
  MQTT_PORT: "1883"
kind: ConfigMap
metadata:
  annotations:
    katenary.v3/compose-hash: 4dd006301f669d044c60fd579bb24fb08133f26f
    katenary.v3/version: release-3.0.0-rc2
  labels:
    {{- include "image_based_video_search.labels" . | nindent 4 }}
    katenary.v3/component: dlstreamer-pipeline-server
  name: '{{ include "image_based_video_search.fullname" . }}-dlstreamer-pipeline-server-env'
---
apiVersion: v1
data:
  config.cpu.json: |
    {
        "config": {
            "pipelines": [
                {
                    "name": "filter-pipeline",
                    "source": "gstreamer",
                    "queue_maxsize": 50,
                    "pipeline": "{auto_source} name=source ! decodebin3 !  gvadetect model=/models/public/yolo11s/FP16/yolo11s.xml  batch_size=1 inference-interval=1 nireq=2 threshold=0.7 model-instance-id=instcpu0 name=detection device=CPU ! queue ! gvainference model=/models/resnet-50-pytorch/FP32/resnet-50-pytorch.xml inference-region=1 name=classification model-instance-id=infer1 device=CPU ! queue ! videoconvertscale ! gvametaconvert add-tensor-data=true name=metaconvert ! jpegenc ! appsink name=destination",
                    "auto_start": false,
                    "mqtt_publisher": {
                        "publish_frame": true,
                        "topic": "edge_video_analytics_results"
                    }
                },
                {
                    "name": "search_image",
                    "source": "image_ingestor",
                    "queue_maxsize": 50,
                    "pipeline": "appsrc name=source  ! decodebin3 ! gvainference model=/models/resnet-50-pytorch/FP32/resnet-50-pytorch.xml model-instance-id=infer2 device=CPU ! gvametaconvert add-tensor-data=true ! appsink name=destination"
                }
            ]
        }
    }
  config.gpu.json: |
    {
        "config": {
            "pipelines": [
                {
                    "name": "filter-pipeline",
                    "source": "gstreamer",
                    "queue_maxsize": 50,
                    "pipeline": "{auto_source} name=source ! decodebin3 !  gvadetect model=/models/public/yolo11s/FP16/yolo11s.xml batch_size=1 inference-interval=1 inference-region=0 nireq=2 threshold=0.7 model-instance-id=instgpu0 name=detection device=GPU ! queue ! gvainference model=/models/resnet-50-pytorch/FP32/resnet-50-pytorch.xml inference-region=1 device=GPU model-instance-id=classify1 ! queue ! vapostproc ! videoconvertscale ! gvametaconvert add-tensor-data=true name=metaconvert ! jpegenc ! appsink name=destination",
                    "auto_start": false,
                    "mqtt_publisher": {
                        "publish_frame": true,
                        "topic": "edge_video_analytics_results"
                    }
                },
                {
                    "name": "search_image",
                    "source": "image_ingestor",
                    "queue_maxsize": 50,
                    "pipeline": "appsrc name=source  ! decodebin3 ! gvainference model=/models/resnet-50-pytorch/FP32/resnet-50-pytorch.xml model-instance-id=infer2 device=GPU ! gvametaconvert add-tensor-data=true ! appsink name=destination"
                }
            ]
        }
    }
  config.npu.json: |
    {
        "config": {
            "pipelines": [
                {
                    "name": "filter-pipeline",
                    "source": "gstreamer",
                    "queue_maxsize": 50,
                    "pipeline": "{auto_source} ! decodebin3 ! gvadetect model=/models/public/yolo11s/FP16/yolo11s.xml  batch_size=1 inference-interval=1 nireq=2 threshold=0.7 model-instance-id=instnpu0 name=detection device=NPU ! queue ! gvainference model=/models/resnet-50-pytorch/FP32/resnet-50-pytorch.xml inference-region=1 device=NPU model-instance-id=infer1 ! queue ! vapostproc ! videoconvertscale ! gvametaconvert add-tensor-data=true name=metaconvert ! jpegenc ! appsink name=destination",
                    "auto_start": false,
                    "mqtt_publisher": {
                        "publish_frame": true,
                        "topic": "edge_video_analytics_results"
                    }
                },
                {
                    "name": "search_image",
                    "source": "image_ingestor",
                    "queue_maxsize": 50,
                    "pipeline": "appsrc name=source  ! decodebin3 ! gvainference model=/models/resnet-50-pytorch/FP32/resnet-50-pytorch.xml model-instance-id=infer2 device=NPU ! gvametaconvert add-tensor-data=true ! appsink name=destination"
                }
            ]
        }
    }
  person-vehicle-bike-detection-2004.json: |
    {
        "json_schema_version": "2.2.0",
        "input_preproc": [],
        "output_postproc": [
            {
                "converter": "boxes_labels",
                "labels": [
                    "vehicle",
                    "person",
                    "bike"
                ]
            }
        ]
    }
kind: ConfigMap
metadata:
  annotations:
    katenary.v3/compose-hash: 4dd006301f669d044c60fd579bb24fb08133f26f
    katenary.v3/version: release-3.0.0-rc2
  labels:
    {{- include "image_based_video_search.labels" . | nindent 4 }}
    katenary.v3/component: dlstreamer-pipeline-server
  name: '{{ include "image_based_video_search.fullname" . }}-dlstreamer-pipeline-server-pipeline'
